5월 24일 금 → ※ ▶ ◈ ∴ 🫡 ❤ …

-----------------------------------------------------------------
오류 메시지 : [ERROR:0@5.758] global obsensor_uvc_stream_channel.cpp:159 cv::obsensor::getStreamChannelGroup Camera index out of range는 
 카메라 장치를 찾지 못했을 때 발생합니다. 여기서는 동영상 파일을 읽기 위한 경로 대신 카메라 인덱스를 사용했기 때문에 발생한 것입니다.

만약 카메라로부터 영상을 읽는 것이 아니라 비디오 파일을 처리하고자 한다면 video_path에 파일 경로를 제공해야 합니다. 예를 들어, pre.detect_objects('path_to_video.mp4')처럼 사용해야 합니다. 그러나 현재 코드에서는 비디오 파일 경로 대신 인덱스 0을 전달하고 있습니다. 카메라 인덱스 대신 파일 경로를 전달하는 방식으로 수정해 보겠습니다.

그리고 YOLO 모델 결과를 플로팅할 때 올바르게 처리되고 있는지, 해당 프레임을 cv2.VideoWriter로 제대로 작성하고 있는지도 확인해 보겠습니다.

아래는 수정된 코드입니다:

…
이제 detect_objects 메서드가 비디오 파일 경로를 인수로 받아 처리하도록 수정되었습니다. 다음과 같은 파일 경로를 제공하여 호출해야 합니다:

video_path = 'path_to_video.mp4'  # 예: 'C:/path/to/your/video.mp4'
output_path = pre.detect_objects(video_path)
> 비디오 파일을 제대로 열 수 없을 때 오류 메시지를 출력하도록 코드가 추가되었습니다. 카메라에서 직접 영상을 읽고자 한다면 카메라가 제대로 연결되어 있는지, 그리고 인덱스가 올바른지 확인해야 합니다. 파일 경로 대신 카메라 인덱스 0을 사용하고 싶다면, 카메라가 시스템에 연결되어 있어야 합니다:

사진 이후
pre.detect_objects(0)

위의 코드가 예상대로 작동하지 않으면, 올바른 비디오 파일 경로를 제공하거나 카메라 연결을 확인해 보세요.

----

>> predict는 yolo에서 객체 검출하는데 사용되는 건가요?

predict 클래스는 YOLO 모델을 사용하여 객체를 검출하는 데 사용됩니다. YOLO(You Only Look Once)는 실시간 객체 검출을 위해 널리 사용되는 딥러닝 모델입니다. 이 클래스는 주어진 비디오 파일이나 스트림에서 프레임별로 객체를 검출하고, 결과를 저장합니다.

YOLO 모델의 사용을 포함하여 객체 검출 과정을 설명하면 다음과 같습니다:

YOLO 모델 로드: YOLO 모델을 로드합니다. 이 모델은 사전 학습된 가중치를 사용하여 객체 검출을 수행합니다.
비디오 캡처: OpenCV를 사용하여 비디오 파일을 열거나 카메라 스트림을 캡처합니다.
프레임 단위로 객체 검출: 비디오의 각 프레임에서 객체를 검출하고, 검출된 객체를 시각화합니다.
결과 저장: 검출 결과가 포함된 비디오를 저장합니다.
아래는 YOLO 모델을 사용하여 객체를 검출하는 Predict 클래스의 구현 코드입니다:

import cv2
from ultralytics import YOLO
import datetime
import os

class Predict:
    def __init__(self):
        self.size = (960, 540)
        # YOLO 모델 로드
        self.model = YOLO('./model_train/runs/detect/train/weights/best.pt')
        self.labels = []
        # 객체 검출에 사용할 레이블 파일 로드 (필요시)
        # with open("C:/Users/602-13/k/label.txt", "r", encoding="utf-8") as f:
        #     self.labels = [line.strip() for line in f.readlines()]

    def detect_objects(self, video_path):
        # 비디오 파일 또는 카메라 스트림 열기
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"Error opening video file or camera: {video_path}")
            return None
        
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        date = datetime.date.today()
        directory = "static/results"
        if not os.path.exists(directory):
            os.makedirs(directory)

        filename = f"{date.strftime('%Y-%m-%d')}_yolo.avi"
        filepath = os.path.join(directory, filename)
        fourcc = cv2.VideoWriter_fourcc(*'XVID')
        out = cv2.VideoWriter(filepath, fourcc, fps, self.size)

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            resized_frame = cv2.resize(frame, self.size)
            # YOLO 모델을 사용하여 객체 검출
            results = self.model(resized_frame)
            # 결과를 시각화하여 이미지로 변환
            plots = results[0].plot()
            bgr_plots = cv2.cvtColor(plots, cv2.COLOR_RGB2BGR)
            out.write(bgr_plots)

        cap.release()
        out.release()
        return filepath

pre = Predict()

# 동영상 파일 경로 또는 카메라 인덱스를 여기에 입력합니다.
video_path = 'path_to_video.mp4'  # 예: 'C:/path/to/your/video.mp4'
output_path = pre.detect_objects(video_path)
if output_path:
    print(f"Detection completed. Output saved to {output_path}")


>> 이 클래스에서:

__init__ 메서드는 YOLO 모델과 필요한 변수를 초기화합니다.
detect_objects 메서드는 비디오 파일 경로 또는 카메라 인덱스를 입력으로 받아 객체를 검출합니다. 검출된 객체가 표시된 프레임을 저장한 비디오 파일의 경로를 반환합니다.
객체 검출을 수행하려면 video_path 변수에 비디오 파일 경로를 제공하거나 카메라 인덱스를 전달하면 됩니다. 비디오 파일 경로를 지정한 경우, 해당 파일에서 객체를 검출하고 결과를 저장합니다. 카메라 인덱스를 전달한 경우, 연결된 카메라 스트림에서 실시간으로 객체를 검출합니다.

----

▶ app.py 코드를 분석하자!

>> 코드는 사용자 인증, 로그 관리 및 업로드된 비디오 파일에서 객체 감지 기능을 갖춘 CCTV 관리 시스템의 Flask 웹 응용 프로그램을 구현합니다. 아래는 코드의 상세한 분석입니다.

- Imports 및 설정
...
 Flask: 웹 응용 프로그램을 생성하는 데 사용됩니다.
 sqlite3: SQLite 데이터베이스에 연결합니다.
 Predict: 비디오 파일에서 객체 감지를 처리하는 사용자 정의 클래스( predict.py에서 가져옴).
 app.secret_key: 세션 관리를 위한 비밀 키입니다.
 UPLOAD_FOLDER 및 RESULT_FOLDER: 업로드된 파일과 처리된 파일을 저장하는 디렉토리입니다.

- 데이터베이스 연결
...
 지정된 경로의 SQLite 데이터베이스에 연결합니다.

- 로그 검색 함수
...
 get_logs: cctvlog 테이블에서 모든 로그를 가져옵니다.
 get_logs_by_date: 특정 날짜의 로그를 가져옵니다.

- 라우트 핸들러
로그 관리 (/logs)
...

 POST 요청에서는 로그를 데이터베이스에 추가하고, 모든 로그 데이터를 가져와 페이지를 렌더링합니다.
 그 외의 요청에서는 모든 로그 데이터를 가져와 페이지를 렌더링합니다.

> 나머지 코드는 사용자 인증, CCTV 페이지 및 프레임 렌더링, 파일 업로드 및 객체 검출 등을 위한 라우트 핸들러를 정의합니다.

----
CSS 코드를 사용하여 .index-frame 클래스를 정의하면 index_frame 프레임의 크기를 조정할 수 있습니다. 아래는 예시 코드입니다.

HTML 파일:
<!-- 인덱스 프레임 -->
<iframe src="{{ url_for('index_frame') }}" name="index_frame" class="index-frame"></iframe>

CSS 파일:

<style>
    .index-frame {
        width: 90%; /* 인덱스 프레임 가로 크기를 90%로 설정 */
        height: 60vh; /* 화면 전체의 60% 높이로 설정 */
    }
</style>
이렇게 하면 index_frame 프레임의 크기만 변경되고, 다른 프레임에는 영향을 주지 않습니다.

▶ 다른 CCTV 영상을 같은 페이지에 추가하려면 <video> 요소를 추가하고 각각의 CCTV 영상에 대한 <source> 태그를 지정하면 됩니다. 아래는 예시 코드입니다.
...

위 코드에서 {{ sub_cctv1_file }}, {{ sub_cctv2_file }}, {{ sub_cctv3_file }}는 각각 서브 CCTV 영상 파일의 URL을 나타내는 변수입니다. 이 변수들을 각 서브 CCTV 영상 파일의 실제 URL로 대체하면 됩니다. 이렇게 하면 메인 CCTV 영상 밑에 세 개의 서브 CCTV 영상이 표시됩니다.

- 각 sub CCTV 영상 파일의 실제 URL은 어디서 끌어오는건가요?

>> 서브 CCTV 영상 파일의 실제 URL은 Flask 애플리케이션에서 사용자가 업로드한 비디오 파일과 마찬가지로 어딘가에서 가져와야 합니다. 일반적으로 서브 CCTV 영상 파일은 사용자가 시스템에 업로드한 파일이나 미리 지정된 경로에서 가져옵니다.

예를 들어, 사용자가 CCTV 시스템에 추가한 서브 CCTV 영상 파일을 서버의 특정 디렉토리에 저장하고, Flask 애플리케이션에서는 이 디렉토리의 파일을 읽어와 URL로 반환할 수 있습니다.

서브 CCTV 영상 파일의 실제 URL을 가져오는 방법은 다음과 같습니다:

1. 사용자가 CCTV 시스템에 서브 CCTV 영상 파일을 업로드합니다.
2. 업로드된 파일은 서버의 특정 디렉토리에 저장됩니다.
3. Flask 애플리케이션에서는 해당 디렉토리의 파일을 읽어와 URL로 반환합니다.
4. 반환된 URL을 HTML 템플릿에 전달하여 페이지에 표시합니다.

이것은 Flask 애플리케이션과 관련된 개념적인 설명입니다. 실제 구현은 Flask에서 파일 업로드와 관련된 기능을 구현하고, 업로드된 파일의 경로를 HTML 템플릿에 전달하는 방식으로 이루어집니다.

>> predict.py에서 받아오는걸텐데!
서브 CCTV 영상 파일의 URL을 가져오는 방법은 Flask 애플리케이션에서 predict.py 파일이나 해당 기능을 통해 제공됩니다. 보통 Flask 애플리케이션에서 predict.py 파일이나 그와 유사한 방식으로 객체 감지 결과를 생성하고, 해당 결과 파일의 경로를 HTML 템플릿에 전달하여 페이지에 표시합니다.

일반적으로 다음과 같은 과정을 거쳐 서브 CCTV 영상 파일의 URL을 가져올 수 있습니다:

Flask 애플리케이션에서 predict.py 파일이 실행됩니다.
predict.py 파일은 객체 감지를 수행하고, 각 서브 CCTV 영상 파일에 대한 결과를 생성합니다.
생성된 결과 파일들은 Flask 애플리케이션에서 특정 디렉토리에 저장됩니다.
Flask 애플리케이션은 이 결과 파일들의 경로를 HTML 템플릿에 전달하여 페이지에 표시합니다.
따라서 predict.py 파일에서 객체 감지를 수행하고 그 결과를 생성하며, Flask 애플리케이션에서는 이 결과 파일들의 경로를 가져와 HTML 템플릿에 전달하여 페이지에 표시하는 방식으로 서브 CCTV 영상 파일의 URL을 가져올 수 있습니다.

----

▶{{ sub_cctv1_file }}, {{ sub_cctv2_file }}, {{ sub_cctv3_file }}는 각각 서브 CCTV 영상 파일을 cctv_frame.html에서 sub1,2,3 한정으로 영상 클릭시 크게 볼 수 있도록 코딩을 짜고 싶습니다. 방법을 알려주세요.


 서브 CCTV 영상 파일을 클릭했을 때 해당 영상을 크게 볼 수 있는 방법은 JavaScript를 사용하여 모달 창을 구현하는 것입니다. 모달 창은 사용자가 클릭하면 화면에 팝업되는 창으로, 여기에 원하는 내용을 표시할 수 있습니다. 아래는 모달 창을 구현하는 간단한 방법입니다.

우선, 서브 CCTV 영상 파일을 클릭할 때 해당 영상을 크게 볼 수 있는 모달 창을 만들어야 합니다.

> 위 코드에서는 JavaScript로 모달 창을 표시하고, 서브 CCTV 영상 파일을 클릭하면 해당 영상이 모달 창에서 크게 표시됩니다. 또한 모달 창의 닫기 버튼을 클릭하면 모달이 닫힙니다.

이제 각 서브 CCTV 영상을 클릭할 때 JavaScript 함수를 호출하여 해당 영상을 모달 창에서 표시하도록 수정해야 합니다. 이를 위해 각 서브 CCTV 영상에 onclick 이벤트를 추가하면 됩니다. 아래는 수정된 코드입니다.

cctv_frame.html 파일을 수정하여 서브 CCTV 영상을 클릭했을 때 모달 창을 표시하고 영상을 크게 보여주는 코드입니다.

모달 창 외부를 클릭하여 닫기 버튼 없이 모달을 닫는 방법 말고도, 닫기 버튼을 따로 만들어서 모달을 닫을 수 있습니다. 아래는 닫기 버튼을 따로 만들어서 모달을 닫는 코드입니다.

... 코딩_:

이 코드에서는 모달 내부에 닫기 버튼을 추가하고, 이 버튼을 클릭하면 closeModal() 함수가 호출되어 모달이 닫히도록 구현되었습니다.













































